"""Markdown + Notebook documentation server with Ayu Mirage theme,
sidebar navigation, and sequential prev/next page arrows.

Reads the table of contents from ``myst.yml`` so the page ordering is
defined in a single place (shared with a local Jupyter Book build).
"""

from __future__ import annotations

import re
from pathlib import Path
from typing import Optional

import yaml
from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import HTMLResponse, JSONResponse
import markdown

app = FastAPI()

BASE_DIR = Path(__file__).parent.resolve()

# â”€â”€ Load static assets at startup â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_STYLE = (BASE_DIR / "static" / "style.css").read_text(encoding="utf-8")
_SCRIPT = (BASE_DIR / "static" / "script.js").read_text(encoding="utf-8")
_TEMPLATE = (BASE_DIR / "templates" / "page.html").read_text(encoding="utf-8")

# â”€â”€ Table of contents: flat ordered list from myst.yml â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

PageEntry = dict  # {"file": str, "title": str}


def _parse_toc() -> list[PageEntry]:
    """Read myst.yml and flatten the toc into an ordered page list."""
    myst_path = BASE_DIR / "myst.yml"
    if not myst_path.exists():
        return []
    cfg = yaml.safe_load(myst_path.read_text(encoding="utf-8"))
    toc = cfg.get("project", {}).get("toc", [])
    pages: list[PageEntry] = []

    def _walk(nodes: list[dict]) -> None:
        for node in nodes:
            if "file" in node:
                pages.append({"file": node["file"], "title": node.get("title", "")})
            if "children" in node:
                _walk(node["children"])

    _walk(toc)
    return pages


PAGES: list[PageEntry] = _parse_toc()

# Map normalised URL path â†’ index for O(1) prev/next lookup
_PAGE_INDEX: dict[str, int] = {}
for _i, _p in enumerate(PAGES):
    _norm = _p["file"].replace("\\", "/")
    _PAGE_INDEX[_norm] = _i
    # Also index without extension so /path/theory resolves
    if _norm.endswith(".md"):
        _PAGE_INDEX[_norm[:-3]] = _i
    elif _norm.endswith(".ipynb"):
        _PAGE_INDEX[_norm[:-6]] = _i


def _neighbours(url_path: str) -> tuple[Optional[PageEntry], Optional[PageEntry]]:
    """Return (prev_page, next_page) for the given URL path."""
    key = url_path.lstrip("/").replace("\\", "/")
    idx = _PAGE_INDEX.get(key)
    if idx is None:
        idx = _PAGE_INDEX.get(key + ".md")
    if idx is None:
        idx = _PAGE_INDEX.get(key + ".ipynb")
    if idx is None:
        return None, None
    prev_p = PAGES[idx - 1] if idx > 0 else None
    next_p = PAGES[idx + 1] if idx < len(PAGES) - 1 else None
    return prev_p, next_p


def _page_url(entry: PageEntry) -> str:
    """Turn a toc entry into the server URL."""
    f = entry["file"].replace("\\", "/")
    if f.endswith(".md"):
        f = f[:-3]
    return "/" + f


# â”€â”€ Folders / files to skip entirely in the sidebar tree â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

SKIP_NAMES = {
    ".git",
    "__pycache__",
    ".venv",
    "venv",
    "node_modules",
    ".ipynb_checkpoints",
    "_build",
    "static",
    "templates",
    "data",
    "models",
    "checkpoints",
    "src",
    "environment",
    "scripts",
    "notes",
}
SKIP_PREFIXES = ("cache_",)

# â”€â”€ Sidebar tree builder â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _label(name: str) -> str:
    """Turn a directory/file name into a readable label."""
    parts = name.split("_", 1)
    label = (
        parts[-1]
        if len(parts) == 2 and parts[0].lstrip("0123456789").replace("week", "") == ""
        else name
    )
    return label.replace("_", " ").title()


def _build_tree(directory: Path, current_url: str, depth: int = 0) -> str:
    """Recursively build the sidebar HTML tree for *directory*."""
    entries = sorted(directory.iterdir(), key=lambda p: (p.is_file(), p.name.lower()))
    items: list[str] = []
    for entry in entries:
        if entry.name.startswith(".") or entry.name in SKIP_NAMES:
            continue
        if any(entry.name.startswith(pf) for pf in SKIP_PREFIXES):
            continue
        if entry.is_dir():
            inner = _build_tree(entry, current_url, depth + 1)
            if not inner:
                continue
            items.append(
                f'<div class="tree-folder">'
                f'<div class="folder-label"><i class="arrow">â–¶</i>{_label(entry.name)}</div>'
                f'<div class="folder-children">{inner}</div>'
                f"</div>"
            )
        elif entry.suffix in (".md", ".ipynb"):
            rel = entry.relative_to(BASE_DIR).as_posix()
            url = "/" + (rel[:-3] if rel.endswith(".md") else rel)
            label = _label(entry.stem)
            if entry.suffix == ".ipynb":
                label = f"ğŸ““ {label}"
            active = "active" if url == current_url else ""
            items.append(f'<a class="tree-file {active}" href="{url}">{label}</a>')
    return "".join(items)


# â”€â”€ Prev / Next navigation HTML â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _nav_html(current_url: str) -> str:
    prev_p, next_p = _neighbours(current_url)
    if not prev_p and not next_p:
        return ""
    parts: list[str] = ['<nav class="page-nav">']
    if prev_p:
        parts.append(
            f'<a class="page-nav-prev" href="{_page_url(prev_p)}">'
            f'<span class="nav-dir">â† Previous</span>'
            f'<span class="nav-title">{prev_p["title"]}</span></a>'
        )
    else:
        parts.append("<span></span>")
    if next_p:
        parts.append(
            f'<a class="page-nav-next" href="{_page_url(next_p)}">'
            f'<span class="nav-dir">Next â†’</span>'
            f'<span class="nav-title">{next_p["title"]}</span></a>'
        )
    else:
        parts.append("<span></span>")
    parts.append("</nav>")
    return "\n".join(parts)


# â”€â”€ HTML page assembly â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _page(content_html: str, current_url: str) -> str:
    """Fill the page template with sidebar, nav, and content."""
    sidebar = _build_tree(BASE_DIR, current_url)
    nav = _nav_html(current_url)
    body = content_html + nav
    return (
        _TEMPLATE.replace("__STYLE__", _STYLE)
        .replace("__SCRIPT__", _SCRIPT)
        .replace("__SIDEBAR__", sidebar)
        .replace("__CONTENT__", body)
    )


# â”€â”€ Math protection (keep $â€¦$ / $$â€¦$$ intact through markdown) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_DISPLAY_RE = re.compile(r"\$\$(.*?)\$\$", re.DOTALL)
_INLINE_RE = re.compile(r"(?<!\\)(?<!\$)\$(?!\$)([^\n\$]+?)(?<!\\)\$(?!\$)")


def _protect_math(text: str) -> tuple[str, dict]:
    """Replace math spans with unique placeholders before markdown processing."""
    store: dict[str, str] = {}
    counter = [0]

    def _save(expr: str) -> str:
        key = f"ZZMATH{counter[0]}ZZ"
        counter[0] += 1
        store[key] = expr
        return key

    text = _DISPLAY_RE.sub(lambda m: _save(f"$${m.group(1)}$$"), text)
    text = _INLINE_RE.sub(lambda m: _save(f"${m.group(1)}$"), text)
    return text, store


def _restore_math(html: str, store: dict) -> str:
    for key, value in store.items():
        html = html.replace(key, value)
    return html


# â”€â”€ Cross-link rewriting â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Theory files contain relative links like ../../03_probability/week07_likelihood/theory.md
# These need to be resolved to absolute server URLs.

_HREF_RE = re.compile(r'href="([^"]+)"')


def _rewrite_links(html: str, md_dir: Path) -> str:
    """Resolve relative .md/.ipynb links to absolute server URLs."""

    def _fix(m: re.Match) -> str:
        href = m.group(1)
        # Skip external URLs, anchors, and mailto
        if href.startswith(("http://", "https://", "//", "#", "mailto:")):
            return m.group(0)
        # Split off any fragment (#section)
        fragment = ""
        if "#" in href:
            href, fragment = href.rsplit("#", 1)
            fragment = "#" + fragment
        if not href:
            # Pure anchor link like #section
            return m.group(0)
        # Resolve relative path against the markdown file's directory
        resolved = (md_dir / href).resolve()
        try:
            rel = resolved.relative_to(BASE_DIR).as_posix()
        except ValueError:
            return m.group(0)
        # Strip .md extension for clean URLs
        if rel.endswith(".md"):
            rel = rel[:-3]
        return f'href="/{rel}{fragment}"'

    return _HREF_RE.sub(_fix, html)


# â”€â”€ Markdown rendering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


def _render_md(md_path: Path, current_url: str) -> str:
    if not md_path.exists() or not md_path.is_file():
        raise HTTPException(status_code=404, detail=f"{md_path.relative_to(BASE_DIR)} not found")
    text = md_path.read_text(encoding="utf-8")
    text, math_store = _protect_math(text)
    body = markdown.markdown(
        text,
        extensions=["fenced_code", "tables", "toc"],
    )
    body = _restore_math(body, math_store)
    body = _rewrite_links(body, md_path.parent)
    return _page(body, current_url)


# â”€â”€ Notebook rendering â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_nbconvert_available = False
try:
    from nbconvert import HTMLExporter
    from nbformat import read as nb_read

    _nbconvert_available = True
except ImportError:
    pass


def _render_nb(nb_path: Path, current_url: str) -> str:
    if not nb_path.exists() or not nb_path.is_file():
        raise HTTPException(status_code=404, detail=f"{nb_path.relative_to(BASE_DIR)} not found")
    if not _nbconvert_available:
        raise HTTPException(
            status_code=500,
            detail="nbconvert is not installed â€” run: pip install nbconvert",
        )
    with open(nb_path, encoding="utf-8") as f:
        notebook = nb_read(f, as_version=4)
    exporter = HTMLExporter(template_name="basic")
    body, _ = exporter.from_notebook_node(notebook)
    return _page(body, current_url)


# â”€â”€ Full-text search index â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_SEARCH_INDEX: list[dict] = []  # [{"file": str, "url": str, "title": str, "text": str}]

# strip markdown formatting for plain-text index
_MD_STRIP_RE = re.compile(
    r"(?:"
    r"\[([^\]]*)\]\([^)]*\)"  # [text](url) â†’ text
    r"|```[\s\S]*?```"  # fenced code blocks
    r"|`[^`]+`"  # inline code
    r"|\$\$[\s\S]*?\$\$"  # display math
    r"|\$[^$\n]+\$"  # inline math
    r"|[#*_~>|`]"  # leftover md punctuation
    r")"
)


def _build_search_index() -> None:
    """Walk all theory.md files and build a plain-text search index."""
    _SEARCH_INDEX.clear()
    for md_path in sorted(BASE_DIR.rglob("theory.md")):
        rel = md_path.relative_to(BASE_DIR).as_posix()
        # skip anything in hidden/build dirs
        parts = rel.split("/")
        if any(p.startswith(".") or p.startswith("_") or p in SKIP_NAMES for p in parts):
            continue
        url = "/" + rel[:-3]  # strip .md
        raw = md_path.read_text(encoding="utf-8")
        # Extract title from first H1
        title_m = re.search(r"^#\s+(.+)$", raw, re.MULTILINE)
        title = title_m.group(1).strip() if title_m else rel
        # Strip markdown to plain text for searching
        text = _MD_STRIP_RE.sub(lambda m: m.group(1) or " ", raw)
        text = re.sub(r"\s+", " ", text).strip()
        _SEARCH_INDEX.append({"file": rel, "url": url, "title": title, "text": text})


_build_search_index()


# â”€â”€ Routes â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€


@app.get("/api/search", response_class=JSONResponse)
def api_search(q: str = Query("", min_length=0)):
    """Full-text search across all theory.md files. Returns JSON results with
    matching snippets (context around each hit)."""
    query = q.strip().lower()
    if len(query) < 2:
        return []
    results: list[dict] = []
    for doc in _SEARCH_INDEX:
        text_lower = doc["text"].lower()
        idx = text_lower.find(query)
        if idx == -1:
            continue
        # Count occurrences
        count = text_lower.count(query)
        # Build snippet: Â±80 chars around first occurrence
        start = max(0, idx - 80)
        end = min(len(doc["text"]), idx + len(query) + 80)
        snippet = doc["text"][start:end]
        if start > 0:
            snippet = "â€¦" + snippet
        if end < len(doc["text"]):
            snippet = snippet + "â€¦"
        results.append(
            {
                "url": doc["url"],
                "title": doc["title"],
                "snippet": snippet,
                "count": count,
            }
        )
    # Sort by number of occurrences (most relevant first)
    results.sort(key=lambda r: r["count"], reverse=True)
    return results[:20]  # cap at 20 results


@app.get("/", response_class=HTMLResponse)
def index():
    intro = BASE_DIR / "intro.md"
    if intro.exists():
        return _render_md(intro, "/intro")
    return _render_md(BASE_DIR / "README.md", "/README")


@app.get("/{full_path:path}", response_class=HTMLResponse)
def serve(full_path: str):
    target = BASE_DIR / full_path
    current_url = "/" + full_path

    # Directory â†’ look for theory.md, then README.md
    if target.is_dir():
        for fallback in ("theory.md", "README.md"):
            candidate = target / fallback
            if candidate.exists():
                rel = candidate.relative_to(BASE_DIR).as_posix()
                url = "/" + (rel[:-3] if rel.endswith(".md") else rel)
                return _render_md(candidate, url)
        raise HTTPException(status_code=404, detail=f"{full_path} not found")

    # Explicit .ipynb
    if target.suffix == ".ipynb" and target.exists():
        return _render_nb(target, current_url)

    # Explicit .md
    if target.suffix == ".md" and target.exists():
        return _render_md(target, current_url.removesuffix(".md"))

    # Extensionless â†’ try .md then .ipynb
    md_alt = target.with_suffix(".md")
    if md_alt.exists():
        return _render_md(md_alt, current_url)

    nb_alt = target.with_suffix(".ipynb")
    if nb_alt.exists():
        return _render_nb(nb_alt, current_url)

    raise HTTPException(status_code=404, detail=f"{full_path} not found")
