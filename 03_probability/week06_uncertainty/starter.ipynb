{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d11d56",
   "metadata": {},
   "source": [
    "# Week 06 — Uncertainty & Statistics\n",
    "\n",
    "This notebook focuses on quantifying uncertainty in predictions. You'll:\n",
    "- Distinguish aleatoric vs epistemic uncertainty\n",
    "- Implement Monte Carlo sampling and bootstrap\n",
    "- Build Bayesian linear regression models\n",
    "- Create calibration and reliability diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5de5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from scipy import stats\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)\n",
    "sns.set_style('whitegrid')\n",
    "print(\"Libraries imported!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c53aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, pickle\n",
    "\n",
    "CACHE_DIR = \"cache_week06\"\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "\n",
    "def save_result(key, obj):\n",
    "    with open(os.path.join(CACHE_DIR, f\"{key}.pkl\"), \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "def load_result(key):\n",
    "    path = os.path.join(CACHE_DIR, f\"{key}.pkl\")\n",
    "    if os.path.exists(path):\n",
    "        with open(path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "def cached(key, compute_fn):\n",
    "    result = load_result(key)\n",
    "    if result is not None:\n",
    "        print(f\"[cache] loaded '{key}'\")\n",
    "        return result\n",
    "    print(f\"[cache] computing '{key}'...\")\n",
    "    result = compute_fn()\n",
    "    save_result(key, result)\n",
    "    return result\n",
    "\n",
    "print(\"Cache utilities ready. Results will be stored in:\", CACHE_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e1365a",
   "metadata": {},
   "source": [
    "## 1. Monte Carlo Basics\n",
    "\n",
    "Estimate expectations and construct empirical confidence intervals using Monte Carlo sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63be84cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: Estimate E[f(X)] where X ~ N(0, 1) and f(x) = x^2 + sin(x)\n",
    "\n",
    "def f(x):\n",
    "    \"\"\"Target function\"\"\"\n",
    "    return x**2 + np.sin(x)\n",
    "\n",
    "# Monte Carlo estimation\n",
    "n_samples = 10000\n",
    "samples = np.random.normal(loc=0.0, scale=1.0, size=n_samples)\n",
    "f_samples = f(samples)\n",
    "\n",
    "# Compute statistics\n",
    "mc_mean = f_samples.mean()\n",
    "mc_std = f_samples.std()\n",
    "lower, upper = np.percentile(f_samples, [2.5, 97.5])\n",
    "\n",
    "print(f\"Monte Carlo Estimate:\")\n",
    "print(f\"  E[f(X)] ≈ {mc_mean:.4f}\")\n",
    "print(f\"  Std[f(X)] ≈ {mc_std:.4f}\")\n",
    "print(f\"  95% CI: [{lower:.4f}, {upper:.4f}]\")\n",
    "\n",
    "# Visualize distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(samples, bins=50, alpha=0.7, density=True, label='Samples')\n",
    "x_range = np.linspace(-4, 4, 100)\n",
    "plt.plot(x_range, stats.norm.pdf(x_range), 'r-', linewidth=2, label='True N(0,1)')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Input Distribution')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(f_samples, bins=50, alpha=0.7, color='green', density=True)\n",
    "plt.axvline(mc_mean, color='red', linestyle='--', linewidth=2, label=f'Mean: {mc_mean:.2f}')\n",
    "plt.axvline(lower, color='blue', linestyle=':', linewidth=2, label=f'2.5%: {lower:.2f}')\n",
    "plt.axvline(upper, color='blue', linestyle=':', linewidth=2, label=f'97.5%: {upper:.2f}')\n",
    "plt.xlabel('f(X)')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Output Distribution f(X) = X² + sin(X)')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae5a3f4",
   "metadata": {},
   "source": [
    "## 2. Bootstrap for Confidence Intervals\n",
    "\n",
    "Implement nonparametric bootstrap to estimate uncertainty in statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2776d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def bootstrap_stat(data, stat_fn, n_boot=1000, alpha=0.05):\n",
    "    n = len(data)\n",
    "    boot_stats = [stat_fn(np.random.choice(data, size=n, replace=True)) for _ in range(n_boot)]\n",
    "    boot_stats = np.array(boot_stats)\n",
    "    ci = np.percentile(boot_stats, [100*alpha/2, 100*(1-alpha/2)])\n",
    "    return stat_fn(data), ci, boot_stats\n",
    "\n",
    "true_mean = 5.0\n",
    "np.random.seed(42)\n",
    "data = np.random.exponential(scale=true_mean, size=50)\n",
    "\n",
    "def _run_bootstrap():\n",
    "    mean_est, mean_ci, mean_boots     = bootstrap_stat(data, np.mean,   n_boot=2000)\n",
    "    median_est, median_ci, med_boots  = bootstrap_stat(data, np.median, n_boot=2000)\n",
    "    return mean_est, mean_ci, mean_boots, median_est, median_ci, med_boots\n",
    "\n",
    "(mean_est, mean_ci, mean_boots,\n",
    " median_est, median_ci, median_boots) = cached(\"bootstrap_mean_median_2000\", _run_bootstrap)\n",
    "\n",
    "print(f\"Mean:   estimate={mean_est:.3f}, 95% CI=[{mean_ci[0]:.3f}, {mean_ci[1]:.3f}]\")\n",
    "print(f\"Median: estimate={median_est:.3f}, 95% CI=[{median_ci[0]:.3f}, {median_ci[1]:.3f}]\")\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "for i, (boots, est, ci, label, color) in enumerate([\n",
    "        (mean_boots,   mean_est,   mean_ci,   'Mean',   'blue'),\n",
    "        (median_boots, median_est, median_ci, 'Median', 'green')]):\n",
    "    plt.subplot(1, 2, i+1)\n",
    "    plt.hist(boots, bins=40, alpha=0.7, color=color, density=True)\n",
    "    plt.axvline(est,   color='red',    linestyle='--', linewidth=2, label=f'Est: {est:.2f}')\n",
    "    plt.axvline(ci[0], color='orange', linestyle=':',  linewidth=2)\n",
    "    plt.axvline(ci[1], color='orange', linestyle=':',  linewidth=2, label='95% CI')\n",
    "    plt.xlabel(f'Bootstrap {label}'); plt.ylabel('Density')\n",
    "    plt.title(f'Bootstrap distribution of {label}'); plt.legend(); plt.grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de5435f",
   "metadata": {},
   "source": [
    "## 3. Bayesian Linear Regression (Simple Implementation)\n",
    "\n",
    "Implement Bayesian linear regression to obtain posterior distributions over parameters and predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc160591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BayesianLinearRegression:\n",
    "    def __init__(self, alpha=1.0, beta=1.0):\n",
    "        self.alpha = alpha; self.beta = beta\n",
    "        self.mu_post = None; self.Sigma_post = None\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        n, d = X.shape\n",
    "        self.Sigma_post = np.linalg.inv(self.alpha * np.eye(d) + self.beta * X.T @ X)\n",
    "        self.mu_post = self.beta * self.Sigma_post @ X.T @ y\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, return_std=True):\n",
    "        mu_pred = X @ self.mu_post\n",
    "        if return_std:\n",
    "            var_pred = 1.0/self.beta + np.sum(X @ self.Sigma_post * X, axis=1)\n",
    "            return mu_pred, np.sqrt(var_pred)\n",
    "        return mu_pred\n",
    "\n",
    "np.random.seed(42)\n",
    "n_train = 20\n",
    "X_train_blr = np.linspace(0, 10, n_train).reshape(-1, 1)\n",
    "X_train_blr_bias = np.hstack([np.ones((n_train, 1)), X_train_blr])\n",
    "y_train_blr = 2 + 0.5 * X_train_blr.ravel() + np.random.randn(n_train) * 0.5\n",
    "\n",
    "def _fit_blr():\n",
    "    blr = BayesianLinearRegression(alpha=0.1, beta=4.0)\n",
    "    blr.fit(X_train_blr_bias, y_train_blr)\n",
    "    return blr\n",
    "\n",
    "blr = cached(\"bayesian_linear_regression_n20\", _fit_blr)\n",
    "\n",
    "X_test_blr = np.linspace(-1, 11, 100).reshape(-1, 1)\n",
    "X_test_blr_bias = np.hstack([np.ones((100, 1)), X_test_blr])\n",
    "mu_pred, std_pred = blr.predict(X_test_blr_bias, return_std=True)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_train_blr, y_train_blr, color='blue', s=50, alpha=0.7, label='Training data')\n",
    "plt.plot(X_test_blr, mu_pred, 'r-', linewidth=2, label='Posterior mean')\n",
    "plt.fill_between(X_test_blr.ravel(), mu_pred - 2*std_pred, mu_pred + 2*std_pred,\n",
    "                 alpha=0.2, color='red', label='±2σ')\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Bayesian Linear Regression')\n",
    "plt.legend(); plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "for _ in range(50):\n",
    "    w_sample = np.random.multivariate_normal(blr.mu_post, blr.Sigma_post)\n",
    "    plt.plot(X_test_blr, X_test_blr_bias @ w_sample, 'b-', alpha=0.1, linewidth=1)\n",
    "plt.scatter(X_train_blr, y_train_blr, color='red', s=50, alpha=0.7, label='Training data', zorder=5)\n",
    "plt.plot(X_test_blr, mu_pred, 'r-', linewidth=3, label='Posterior mean', zorder=10)\n",
    "plt.xlabel('x'); plt.ylabel('y'); plt.title('Posterior Samples')\n",
    "plt.legend(); plt.grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "print(f\"Posterior mean: {blr.mu_post}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c837f",
   "metadata": {},
   "source": [
    "## 4. Calibration and Reliability Diagrams\n",
    "\n",
    "Assess whether predicted uncertainties are well-calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a4c5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate test data to evaluate calibration\n",
    "np.random.seed(123)\n",
    "n_test = 200\n",
    "X_test_calib = np.random.uniform(0, 10, n_test).reshape(-1, 1)\n",
    "X_test_calib_bias = np.hstack([np.ones((n_test, 1)), X_test_calib])\n",
    "y_test_true = 2 + 0.5 * X_test_calib.ravel() + np.random.randn(n_test) * 0.5\n",
    "\n",
    "# Predict\n",
    "mu_test, std_test = blr.predict(X_test_calib_bias, return_std=True)\n",
    "\n",
    "# Compute standardized residuals\n",
    "z_scores = (y_test_true - mu_test) / std_test\n",
    "\n",
    "# Check calibration: z_scores should be ~ N(0, 1)\n",
    "print(\"Calibration Check:\")\n",
    "print(f\"  Mean of z-scores: {z_scores.mean():.3f} (should be ~0)\")\n",
    "print(f\"  Std of z-scores: {z_scores.std():.3f} (should be ~1)\")\n",
    "\n",
    "# Empirical coverage\n",
    "coverage_levels = [0.5, 0.68, 0.95, 0.99]\n",
    "print(\"\\nEmpirical Coverage:\")\n",
    "for level in coverage_levels:\n",
    "    z_crit = stats.norm.ppf((1 + level) / 2)\n",
    "    in_interval = np.abs(z_scores) <= z_crit\n",
    "    empirical_coverage = in_interval.mean()\n",
    "    print(f\"  {level*100:.0f}% interval: {empirical_coverage*100:.1f}% coverage (expected {level*100:.0f}%)\")\n",
    "\n",
    "# Reliability diagram\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(z_scores, bins=30, density=True, alpha=0.7, label='Empirical')\n",
    "x_range = np.linspace(-4, 4, 100)\n",
    "plt.plot(x_range, stats.norm.pdf(x_range), 'r-', linewidth=2, label='N(0,1)')\n",
    "plt.xlabel('Standardized Residuals')\n",
    "plt.ylabel('Density')\n",
    "plt.title('Calibration: Standardized Residuals')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "stats.probplot(z_scores, dist=\"norm\", plot=plt)\n",
    "plt.title('Q-Q Plot')\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "# Coverage plot\n",
    "confidence_levels = np.linspace(0.1, 0.99, 20)\n",
    "empirical_coverages = []\n",
    "for level in confidence_levels:\n",
    "    z_crit = stats.norm.ppf((1 + level) / 2)\n",
    "    in_interval = np.abs(z_scores) <= z_crit\n",
    "    empirical_coverages.append(in_interval.mean())\n",
    "\n",
    "plt.plot(confidence_levels, empirical_coverages, 'o-', linewidth=2, label='Empirical')\n",
    "plt.plot([0, 1], [0, 1], 'r--', linewidth=2, label='Perfect calibration')\n",
    "plt.xlabel('Predicted Confidence Level')\n",
    "plt.ylabel('Empirical Coverage')\n",
    "plt.title('Reliability Diagram')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c060f40",
   "metadata": {},
   "source": [
    "## Exercises for Further Practice\n",
    "\n",
    "1. **Heteroscedastic Modeling**: Build a model that predicts both mean and variance\n",
    "2. **PyMC3 Bayesian Regression**: Implement full Bayesian regression using PyMC3 or NumPyro\n",
    "3. **Conformal Prediction**: Implement distribution-free prediction intervals\n",
    "4. **Ensemble Uncertainty**: Train multiple models and compare ensemble uncertainty to single-model uncertainty\n",
    "5. **Real Dataset**: Apply uncertainty quantification to a real regression problem\n",
    "\n",
    "## Deliverables Checklist\n",
    "\n",
    "- [ ] Monte Carlo estimation with confidence intervals\n",
    "- [ ] Bootstrap implementation and comparison to analytic intervals\n",
    "- [ ] Bayesian linear regression with posterior predictive checks\n",
    "- [ ] Calibration assessment with reliability diagrams\n",
    "- [ ] Mini-project: uncertainty quantification on real or synthetic data\n",
    "\n",
    "## Recommended Resources\n",
    "\n",
    "- Murphy, \"Machine Learning: A Probabilistic Perspective\" (Bayesian inference chapter)\n",
    "- \"Bayesian Methods for Hackers\" (practical PyMC examples)\n",
    "- Scikit-learn docs on calibration and model evaluation\n",
    "- Gelman et al., \"Bayesian Data Analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1b259c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXERCISE 1 — Online Bayesian Updating\n",
    "# Goal: start with the BLR prior. Feed data points one at a time (n=1 to 20).\n",
    "# Plot the posterior predictive interval at each step, showing how it shrinks.\n",
    "# Use cached(\"blr_sequential_updates_n20\", ...) to save the list of (mu, Sigma) pairs.\n",
    "# Expected insight: uncertainty decreases as more data arrives (fundamental Bayesian idea).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c4d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXERCISE 2 — Ensemble Uncertainty\n",
    "# Goal: train 10 linear regression models, each on a different bootstrap subsample.\n",
    "# At each test point, compute the mean and std of predictions across models.\n",
    "# Plot error bars and compare to BLR's posterior predictive interval.\n",
    "# Use cached(\"ensemble_uncertainty_10models\", ...) to save the ensemble coefficients.\n",
    "# Expected insight: ensemble spread ≈ epistemic uncertainty; wider in out-of-distribution regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d496ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# EXERCISE 4 — Calibration on Real Data\n",
    "# Goal: pick sklearn's diabetes dataset (regression) or any classification dataset.\n",
    "# Fit a Ridge model and build 95% prediction intervals using the BLR approach above.\n",
    "# Compute the empirical coverage and plot a reliability diagram.\n",
    "# Deliverable: one paragraph on whether the model is well-calibrated and why.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
