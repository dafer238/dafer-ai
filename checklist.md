# 16-Week AI Study Program – Printable Weekly Checklist

Use this as a **tick-box execution plan**. Each week assumes ~10–12 focused hours. Do not rush checkpoints; understanding beats speed.

---

## Week 1 – Optimization Intuition (Loss as Energy)

**Study**

* ☐ Loss functions as energy landscapes
* ☐ Gradients as forces
* ☐ Convex vs non-convex intuition

**Build**

* ☐ Implement gradient descent in NumPy
* ☐ Visualize loss surfaces (2D/3D)

**Checkpoint**

* ☐ Can explain why large learning rates diverge
* ☐ Can explain momentum without equations

**Mini-project**

* ☐ Estimate thermal parameters of a simple building heat model

---

## Week 2 – Advanced Optimization

**Study**

* ☐ SGD vs Momentum vs Adam
* ☐ Learning rate schedules

**Build**

* ☐ Compare optimizers on same loss
* ☐ Plot convergence behavior

**Checkpoint**

* ☐ Understand why Adam converges fast but may generalize worse

**Mini-project**

* ☐ Energy system parameter fitting with noisy data

---

## Week 3 – Classical ML Foundations

**Study**

* ☐ Supervised learning basics
* ☐ Bias–variance tradeoff

**Build**

* ☐ Linear regression from scratch
* ☐ Logistic regression from scratch

**Checkpoint**

* ☐ Can diagnose underfitting vs overfitting numerically

**Mini-project**

* ☐ Simple return prediction model (linear factors)

---

## Week 4 – Regularization & Validation

**Study**

* ☐ L1 vs L2 regularization
* ☐ Cross-validation

**Build**

* ☐ Ridge and Lasso implementations

**Checkpoint**

* ☐ Can explain regularization as constraint/entropy control

**Mini-project**

* ☐ Stable factor selection for financial returns

---

## Week 5 – Probability & Noise

**Study**

* ☐ Likelihood vs loss
* ☐ Gaussian assumptions

**Build**

* ☐ MLE for Gaussian noise

**Checkpoint**

* ☐ Can derive squared-error loss from Gaussian likelihood

**Mini-project**

* ☐ Sensor noise modeling with uncertainty bounds

---

## Week 6 – Uncertainty & Statistics

**Study**

* ☐ Noise vs signal
* ☐ Confidence intervals

**Build**

* ☐ Monte Carlo simulations

**Checkpoint**

* ☐ Can explain when probabilistic models fail

**Mini-project**

* ☐ Industrial measurement uncertainty analysis

---

## Week 7 – Neural Networks From Scratch

**Study**

* ☐ Neurons, activations, layers
* ☐ Chain rule for backprop

**Build**

* ☐ Fully connected NN in NumPy

**Checkpoint**

* ☐ Can derive backprop on paper

**Mini-project**

* ☐ Nonlinear energy demand model

---

## Week 8 – Training Pathologies

**Study**

* ☐ Vanishing/exploding gradients
* ☐ Initialization

**Build**

* ☐ Compare activations

**Checkpoint**

* ☐ Can debug unstable training

**Mini-project**

* ☐ Demand forecasting stress tests

---

## Week 9 – PyTorch Fundamentals

**Study**

* ☐ Autograd
* ☐ Computational graphs

**Build**

* ☐ Rewrite NN in PyTorch

**Checkpoint**

* ☐ Understand what autograd stores

**Mini-project**

* ☐ Volatility regime classifier

---

## Week 10 – Efficient Training

**Study**

* ☐ Batching
* ☐ GPU utilization

**Build**

* ☐ DataLoaders and schedulers

**Checkpoint**

* ☐ Can explain batch size tradeoffs

**Mini-project**

* ☐ Improved regime detection model

---

## Week 11 – Representation Learning

**Study**

* ☐ Feature hierarchies
* ☐ Overfitting in deep models

**Build**

* ☐ CNN basics

**Checkpoint**

* ☐ Understand inductive bias

**Mini-project**

* ☐ Fault detection from sensor windows

---

## Week 12 – Regularization at Scale

**Study**

* ☐ Dropout
* ☐ BatchNorm

**Build**

* ☐ CNN with regularization

**Checkpoint**

* ☐ Know when regularization hurts

**Mini-project**

* ☐ Robust industrial fault classifier

---

## Week 13 – Sequential Models

**Study**

* ☐ Temporal dependencies
* ☐ Attention concept

**Build**

* ☐ Attention mechanism from scratch

**Checkpoint**

* ☐ Can explain attention intuitively

**Mini-project**

* ☐ Time-series energy price forecasting

---

## Week 14 – Transformers

**Study**

* ☐ Positional encoding
* ☐ Transformer blocks

**Build**

* ☐ Small transformer model

**Checkpoint**

* ☐ Understand scaling limits

**Mini-project**

* ☐ Transformer vs LSTM comparison

---

## Week 15 – Fine-Tuning & Transfer

**Study**

* ☐ Transfer learning
* ☐ Adapters vs full fine-tuning

**Build**

* ☐ Fine-tune pretrained model

**Checkpoint**

* ☐ Know when not to fine-tune

**Mini-project**

* ☐ Domain-adapted forecasting model

---

## Week 16 – Deployment & Capstone

**Study**

* ☐ Inference constraints
* ☐ Latency vs accuracy

**Build**

* ☐ Package model as API

**Checkpoint**

* ☐ End-to-end system understanding

**Capstone (choose one)**

* ☐ Energy optimization system
* ☐ Quantitative trading signal with uncertainty
* ☐ Industrial fault prediction pipeline

---

## Final Validation

* ☐ Can explain training dynamics without slides
* ☐ Can debug models without guessing
* ☐ Can connect AI behavior to physical/financial intuition

**If all boxes are checked: you are no longer a user of AI — you are a builder.**
