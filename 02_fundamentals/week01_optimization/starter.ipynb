{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67151a4d",
   "metadata": {},
   "source": [
    "# Week 01 â€” Optimization Intuition (Loss as Energy)\n",
    "\n",
    "This notebook guides you through building physical intuition for loss landscapes and optimization dynamics. You'll:\n",
    "- Visualize loss landscapes and understand gradient-based optimization\n",
    "- Implement gradient descent, SGD, and momentum\n",
    "- Experiment with learning rates and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e3dc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9175560e",
   "metadata": {},
   "source": [
    "## 1. Visualize Simple Loss Landscapes\n",
    "\n",
    "Create 2D grids and plot loss contours for quadratic and multimodal functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5548dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "def quadratic(x, y):\n",
    "    \"\"\"Simple quadratic loss\"\"\"\n",
    "    return x**2 + 3*y**2\n",
    "\n",
    "def multimodal(x, y):\n",
    "    \"\"\"Multimodal loss with multiple local minima\"\"\"\n",
    "    return np.sin(x) * np.cos(y) + 0.1*(x**2 + y**2)\n",
    "\n",
    "# Create grid\n",
    "x_range = np.linspace(-3, 3, 100)\n",
    "y_range = np.linspace(-3, 3, 100)\n",
    "X, Y = np.meshgrid(x_range, y_range)\n",
    "\n",
    "# Compute losses\n",
    "Z_quad = quadratic(X, Y)\n",
    "Z_multi = multimodal(X, Y)\n",
    "\n",
    "# Plot contours\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Quadratic\n",
    "contour1 = axes[0].contour(X, Y, Z_quad, levels=20, cmap='viridis')\n",
    "axes[0].set_title('Quadratic Loss Landscape')\n",
    "axes[0].set_xlabel('x')\n",
    "axes[0].set_ylabel('y')\n",
    "plt.colorbar(contour1, ax=axes[0])\n",
    "\n",
    "# Multimodal\n",
    "contour2 = axes[1].contour(X, Y, Z_multi, levels=20, cmap='viridis')\n",
    "axes[1].set_title('Multimodal Loss Landscape')\n",
    "axes[1].set_xlabel('x')\n",
    "axes[1].set_ylabel('y')\n",
    "plt.colorbar(contour2, ax=axes[1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe327623",
   "metadata": {},
   "source": [
    "## 2. Gradient Descent Dynamics\n",
    "\n",
    "Implement vanilla gradient descent and plot parameter trajectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ee1a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent implementation\n",
    "def gradient_descent(x0, y0, grad_fn, lr=0.1, n_steps=50):\n",
    "    \"\"\"\n",
    "    Simple gradient descent optimizer\n",
    "    \n",
    "    Args:\n",
    "        x0, y0: Initial parameters\n",
    "        grad_fn: Function returning (grad_x, grad_y)\n",
    "        lr: Learning rate\n",
    "        n_steps: Number of optimization steps\n",
    "    \n",
    "    Returns:\n",
    "        trajectory: List of (x, y) positions\n",
    "    \"\"\"\n",
    "    trajectory = [(x0, y0)]\n",
    "    x, y = x0, y0\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        gx, gy = grad_fn(x, y)\n",
    "        x -= lr * gx\n",
    "        y -= lr * gy\n",
    "        trajectory.append((x, y))\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "# Define gradients for quadratic loss\n",
    "def quad_gradient(x, y):\n",
    "    return (2*x, 6*y)\n",
    "\n",
    "# Run gradient descent\n",
    "trajectory_gd = gradient_descent(2.0, -1.0, quad_gradient, lr=0.1, n_steps=50)\n",
    "\n",
    "# Plot trajectory on loss landscape\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contour(X, Y, Z_quad, levels=20, cmap='viridis', alpha=0.6)\n",
    "traj_x = [p[0] for p in trajectory_gd]\n",
    "traj_y = [p[1] for p in trajectory_gd]\n",
    "plt.plot(traj_x, traj_y, 'r-o', markersize=4, linewidth=2, label='GD trajectory')\n",
    "plt.plot(traj_x[0], traj_y[0], 'go', markersize=10, label='Start')\n",
    "plt.plot(traj_x[-1], traj_y[-1], 'ro', markersize=10, label='End')\n",
    "plt.title('Gradient Descent on Quadratic Loss')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Final position: ({traj_x[-1]:.4f}, {traj_y[-1]:.4f})\")\n",
    "print(f\"Final loss: {quadratic(traj_x[-1], traj_y[-1]):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d15bc8",
   "metadata": {},
   "source": [
    "## 3. Momentum and Learning Rate Sweeps\n",
    "\n",
    "Implement momentum and experiment with different learning rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9f44fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient descent with momentum\n",
    "def gradient_descent_momentum(x0, y0, grad_fn, lr=0.1, momentum=0.9, n_steps=50):\n",
    "    \"\"\"GD with momentum\"\"\"\n",
    "    trajectory = [(x0, y0)]\n",
    "    x, y = x0, y0\n",
    "    vx, vy = 0.0, 0.0\n",
    "    \n",
    "    for _ in range(n_steps):\n",
    "        gx, gy = grad_fn(x, y)\n",
    "        vx = momentum * vx - lr * gx\n",
    "        vy = momentum * vy - lr * gy\n",
    "        x += vx\n",
    "        y += vy\n",
    "        trajectory.append((x, y))\n",
    "    \n",
    "    return trajectory\n",
    "\n",
    "# Compare GD vs GD+Momentum\n",
    "trajectory_momentum = gradient_descent_momentum(2.0, -1.0, quad_gradient, lr=0.1, momentum=0.9, n_steps=50)\n",
    "\n",
    "# Plot comparison\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.contour(X, Y, Z_quad, levels=20, cmap='viridis', alpha=0.6)\n",
    "\n",
    "# GD trajectory\n",
    "plt.plot(traj_x, traj_y, 'b-o', markersize=3, linewidth=1.5, label='Vanilla GD', alpha=0.7)\n",
    "\n",
    "# Momentum trajectory\n",
    "mom_x = [p[0] for p in trajectory_momentum]\n",
    "mom_y = [p[1] for p in trajectory_momentum]\n",
    "plt.plot(mom_x, mom_y, 'r-o', markersize=3, linewidth=1.5, label='GD + Momentum', alpha=0.7)\n",
    "\n",
    "plt.plot(2.0, -1.0, 'go', markersize=10, label='Start')\n",
    "plt.title('Gradient Descent: Vanilla vs Momentum')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"GD final loss: {quadratic(traj_x[-1], traj_y[-1]):.6f}\")\n",
    "print(f\"Momentum final loss: {quadratic(mom_x[-1], mom_y[-1]):.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176274eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate sweep\n",
    "learning_rates = [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "final_losses = []\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.contour(X, Y, Z_quad, levels=20, cmap='viridis', alpha=0.3)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    traj = gradient_descent(2.0, -1.0, quad_gradient, lr=lr, n_steps=30)\n",
    "    tx = [p[0] for p in traj]\n",
    "    ty = [p[1] for p in traj]\n",
    "    final_loss = quadratic(tx[-1], ty[-1])\n",
    "    final_losses.append(final_loss)\n",
    "    plt.plot(tx, ty, '-o', markersize=2, label=f'LR={lr}', alpha=0.7)\n",
    "\n",
    "plt.title('Learning Rate Sweep on Quadratic Loss')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot final loss vs learning rate\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(learning_rates, final_losses, 'o-', linewidth=2, markersize=8)\n",
    "plt.xlabel('Learning Rate')\n",
    "plt.ylabel('Final Loss')\n",
    "plt.title('Final Loss vs Learning Rate')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45573a8",
   "metadata": {},
   "source": [
    "## Exercises for Further Practice\n",
    "\n",
    "1. **Explore SGD**: Implement stochastic gradient descent with mini-batches on a simple regression dataset\n",
    "2. **Saddle Points**: Create a saddle-point loss function and visualize optimizer behavior\n",
    "3. **Cyclical Learning Rates**: Implement Leslie Smith's cyclical LR and compare to constant LR\n",
    "4. **3D Visualization**: Create 3D surface plots of the loss landscapes\n",
    "5. **Divergence Analysis**: Find learning rates that cause divergence and explain why\n",
    "\n",
    "## Deliverables Checklist\n",
    "\n",
    "- [ ] Loss landscape visualizations (quadratic + multimodal)\n",
    "- [ ] GD/SGD/momentum implementations with trajectory plots\n",
    "- [ ] Learning rate sweep analysis\n",
    "- [ ] Short conclusions about convergence behavior and hyperparameter sensitivity\n",
    "\n",
    "## Recommended Next Steps\n",
    "\n",
    "- Review optimization sections in Goodfellow et al. \"Deep Learning\"\n",
    "- Explore Leslie Smith's LR range test and cyclical LR papers\n",
    "- Try implementing Adam optimizer (Week 02 preview)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
